{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "multi-object-detection.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOvaB27tICwMbIblIXNeBID",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/pytorch-computer-vision-cookbook/blob/main/5-multi-object-detection/multi_object_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rYnu9PNv3NW"
      },
      "source": [
        "# Multi-Object Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8iTz06Xv96_"
      },
      "source": [
        "Object detection is the process of locating and classifying existing objects in an image. Identified objects are shown with bounding boxes in the image. There are two methods for general object detection: region proposal-based and regression/classification-based. \r\n",
        "\r\n",
        "In this notebook, we will use a regression/classification-based method called YOLO.we will learn how to implement the YOLO-v3 algorithm and train and\r\n",
        "deploy it for object detection using PyTorch.\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b08H4QZ1x5Mh"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERXmfyIgx6hn",
        "outputId": "7e737394-89d3-46e2-94e2-cd89e6ec75e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\r\n",
        "import torchvision.transforms.functional as TF\r\n",
        "from torchvision.transforms.functional import to_pil_image\r\n",
        "from torch import optim\r\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\r\n",
        "\r\n",
        "\r\n",
        "import torch\r\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "print(torch.__version__)\r\n",
        "\r\n",
        "from PIL import Image, ImageDraw, ImageFont\r\n",
        "\r\n",
        "import copy\r\n",
        "import os\r\n",
        "import random\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pylab as plt\r\n",
        "\r\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.7.0+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kcx0rArMwN4K"
      },
      "source": [
        "## Creating datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8OY4pK8wPF4"
      },
      "source": [
        "We will need to download the COCO dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAX1F7s3yfDG"
      },
      "source": [
        "%%shell\r\n",
        "\r\n",
        "# Download the following GitHub repository\r\n",
        "git clone https://github.com/pjreddie/darknet\r\n",
        "\r\n",
        "# Create a folder named data\r\n",
        "mkdir data\r\n",
        "\r\n",
        "# copy the get_coco_dataset.sh file\r\n",
        "cp darknet/scripts/get_coco_dataset.sh data\r\n",
        "\r\n",
        "# execute the get_coco_dataset.sh file\r\n",
        "chmod 755 data/get_coco_dataset.sh\r\n",
        "./data/get_coco_dataset.sh\r\n",
        "\r\n",
        "# Create a folder named config\r\n",
        "mkdir data/config\r\n",
        "# copy the yolov3.cfg file\r\n",
        "cp darknet/cfg/yolov3.cfg data/config/\r\n",
        "\r\n",
        "# Finally, download the coco.names file and put it in the data folder\r\n",
        "wget https://github.com/pjreddie/darknet/blob/master/data/coco.names\r\n",
        "cp coco.names data/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHVVh1wl5S8W"
      },
      "source": [
        "### Creating a custom COCO dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7n523yg5U9B"
      },
      "source": [
        "Now that we've downloaded the COCO dataset, we will create training and validation datasets and dataloaders using PyTorch's Dataset and Dataloader classes.\r\n",
        "\r\n",
        "we will define the CocoDataset class and show some sample images from\r\n",
        "the training and validation datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oS3CdwTyz4kQ"
      },
      "source": [
        "class CocoDataset(Dataset):\r\n",
        "\r\n",
        "  def __init__(self, files_path, transform=None, trans_params=None):\r\n",
        "    # get list of images\r\n",
        "    with opne(files_path, \"r\") as file:\r\n",
        "      self.img_path = file.readlines()\r\n",
        "    # get list of labels\r\n",
        "    self.label_path = [path.replace(\"images\", \"labels\").replace(\".png\", \"txt\").replace(\".jpg\", \".txt\") for path in self.img_path]\r\n",
        "    self.trans_params = trans_params \r\n",
        "    self.transform = transform \r\n",
        "\r\n",
        "  def __len__(self):\r\n",
        "    return len(self.img_path)\r\n",
        "\r\n",
        "  def __getitem__(self, index):\r\n",
        "    img_path = self.img_path[index % len(self.img_path)].rstrip()\r\n",
        "    img = Image.open(img_path).convert(\"RGB\")\r\n",
        "    label_path = self.label_path[index % len(self.img_path)].rstrip()\r\n",
        "\r\n",
        "    labels = None\r\n",
        "    if os.path.exists(label_path):\r\n",
        "      labels = np.loadtxt(label_path).replace(-1, 5)\r\n",
        "    if self.transform:\r\n",
        "      img, labels = self.transform(img, labels, self.trans_params)\r\n",
        "\r\n",
        "    return img, labels, img_path"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtPZ47Zq58l1"
      },
      "source": [
        "Next, we will create an object of the CocoDataset class for the validation data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bla3nDy84ett"
      },
      "source": [
        "root_data = \"./data/coco\"\r\n",
        "train_file_path = os.path.join(root_data, \"trainvalno5k.txt\")\r\n",
        "coco_train = CocoDataset(train_file_path)\r\n",
        "print(len(coco_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQEhrvjA6l2r"
      },
      "source": [
        "# Get a sample item from coco_val:\r\n",
        "img, labels, img_path = coco_train[1] \r\n",
        "print(\"image size:\", img.size, type(img))\r\n",
        "print(\"labels shape:\", labels.shape, type(labels))\r\n",
        "print(\"labels \\n\", labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnikLO-r6zVh"
      },
      "source": [
        "Let's display a sample image from the coco_train and coco_val datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYeV0rUw60LL"
      },
      "source": [
        "val_file_path = os.path.join(root_data, \"5k.txt\")\r\n",
        "coco_val = CocoDataset(val_file_path, transform=None, trans_params=None)\r\n",
        "print(len(coco_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7fdGIVLBoAA"
      },
      "source": [
        "# Get a sample item from coco_val:\r\n",
        "img, labels, img_path = coco_val[7] \r\n",
        "print(\"image size:\", img.size, type(img))\r\n",
        "print(\"labels shape:\", labels.shape, type(labels))\r\n",
        "print(\"labels \\n\", labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VE2Z2pSOB75K"
      },
      "source": [
        "Let's display a sample image from the coco_train and coco_val datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llLvc96UB8xN"
      },
      "source": [
        "# Get a list of COCO object names\r\n",
        "coco_names_path=\"./data/coco.names\"\r\n",
        "fp = open(coco_names_path, \"r\")\r\n",
        "coco_names = fp.read().split(\"\\n\")[:-1]\r\n",
        "print(\"number of classese:\", len(coco_names))\r\n",
        "print(coco_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_PWY1bhCUa0"
      },
      "source": [
        "# Define a rescale_bbox helper function to rescale normalized bounding boxes to the original image size\r\n",
        "def rescale_bbox(bb, W, H):\r\n",
        "  x, y, w, h = bb\r\n",
        "  return [x * W, y * H, w * W, h * H]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZZT7wK3Cwlo"
      },
      "source": [
        "# Define the show_img_bbox helper function to show an image with object bounding boxes\r\n",
        "COLORS = np.random.randint(0, 255, size=(80, 3),dtype=\"uint8\")\r\n",
        "# if the font that's passed to ImageFont.truetype is not available\r\n",
        "# Alternatively, you may use a more common font\r\n",
        "# fnt = ImageFont.truetype('arial.ttf', 16)\r\n",
        "fnt = ImageFont.truetype('Pillow/Tests/fonts/FreeMono.ttf', 16)\r\n",
        "\r\n",
        "def show_img_bbox(img, targets):\r\n",
        "  if torch.is_tensor(img):\r\n",
        "      img=to_pil_image(img)\r\n",
        "  if torch.is_tensor(targets):\r\n",
        "      targets=targets.numpy()[:,1:]\r\n",
        "      \r\n",
        "  W, H=img.size\r\n",
        "  draw = ImageDraw.Draw(img)\r\n",
        "  \r\n",
        "  for target in targets:\r\n",
        "      id_=int(target[0])\r\n",
        "      bbox=target[1:]\r\n",
        "      bbox=rescale_bbox(bbox,W,H)\r\n",
        "      xc, yc, w, h=bbox\r\n",
        "      \r\n",
        "      color = [int(c) for c in COLORS[id_]]\r\n",
        "      name=coco_names[id_]\r\n",
        "      \r\n",
        "      draw.rectangle(((xc-w/2, yc-h/2), (xc+w/2, yc+h/2)), outline=tuple(color), width=3)\r\n",
        "      draw.text((xc-w/2, yc-h/2), name, font=fnt, fill=(255, 255, 255, 0))\r\n",
        "  plt.imshow(np.array(img))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWGHUB83DVdE"
      },
      "source": [
        "# Call the show_img_bbox helper function to show a sample image from coco_train\r\n",
        "np.random.seed(2)\r\n",
        "rnd_ind=np.random.randint(len(coco_train))\r\n",
        "img, labels, img_path = coco_train[rnd_ind] \r\n",
        "print(img.size, labels.shape)\r\n",
        "\r\n",
        "plt.rcParams['figure.figsize'] = (20, 10)\r\n",
        "show_img_bbox(img, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QTnFFEmEJBO"
      },
      "source": [
        "# Call the show_img_bbox helper function to show a sample image from coco_val\r\n",
        "np.random.seed(0)\r\n",
        "rnd_ind=np.random.randint(len(coco_val))\r\n",
        "img, labels, img_path = coco_val[rnd_ind] \r\n",
        "print(img.size, labels.shape)\r\n",
        "\r\n",
        "plt.rcParams['figure.figsize'] = (20, 10)\r\n",
        "show_img_bbox(img, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57j3VGL1EIea"
      },
      "source": [
        "### Transforming data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yx1yM6tZEcMM"
      },
      "source": [
        ""
      ]
    }
  ]
}